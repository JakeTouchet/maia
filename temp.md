### Running netdissect

MAIA uses pre-computed exemplars for its experiments. Thus, to run MAIA on a new model, you must first compute the exemplars netdissect. MAIA was built to use exemplar data as generated by MILAN’s implementation of netdissect. 

First, clone MILAN.

```python
git clone https://github.com/evandez/neuron-descriptions.git
```

Then, set the environment variables to control where the data is inputted/outputted. Ex:

```python
%env MILAN_DATA_DIR=./data
%env MILAN_MODELS_DIR=./models
%env MILAN_RESULTS_DIR=./results
```

Make those three directories mentioned above.

When you have a new model you want to dissect:

1. Make a folder in `models` directory
2. Name it whatever you want to call your model (in this case we'll use `resnet18syn`)
3. Inside that folder, place your saved model file, but name it `imagenet.pth` (since you'll be dissecting with ImageNet)

Now, place ImageNet in the data directory. If you have imagenet installed, you create a symbolic link to it using:

```bash
ln -s /path/to/imagenet /path/to/data/imagenet
```

If you don’t have imagenet installed, follow the download instructions [here](https://image-net.org/download.php): 

Next, add under your keys in `models.py` (located in `src/exemplars/models.py`):

```python
KEYS.RESNET18_SYNTHETIC = 'resnet18syn/imagenet'
```

Then add this in the keys dict:

```python
KEYS.RESNET18_SYNTHETIC:
    ModelConfig(
        models.resnet18,
        load_weights=True,
        layers=LAYERS.RESNET18,
    ),
```

Once that's done, you should be ready to run the compute exemplars script:

```bash
python3 -m scripts.compute_exemplars resnet18syn imagenet --device cuda
```

This will run the compute exemplars script using the ResNet18 synthetic model on the ImageNet dataset, utilizing CUDA for GPU acceleration.

Finally, move the computed exemplars to the `exemplars/` folder.

## Updates

- Reworked MAIA’s code execution to run multiple free-form blocks of code, rather than having MAIA define a single function that is then executed
- Reworked MAIA to use a flexible display function which recursively unpacks passed iterables and append them to MAIA’s experiment log
- Refactored MAIA’s api file to be purely front-facing, moving back-end functions to various utils files. Public functions that MAIA executes now follow standard OOP naming conventions
- Re-implemented MAIA as an InterpAgent. The InterpAgent class allows the creation of tools as sub-agents which can execute code given a user and api prompt
- Added gpt-4o, gpt-4o-mini, and gpt-4-turbo
- Unified llm calls to use call_agent.py and the same set of response formatting function
- Changed neuron index file to allow specification of multiple models
- Simplified main.py
- Numerous small clean ups and bugfixes

## TODO

Add guide for generating synthetic exemplars