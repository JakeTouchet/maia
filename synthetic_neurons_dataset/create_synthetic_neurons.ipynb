{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df5e56aa-8ffe-4bc0-ad7e-81237d28b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from synthetic_neurons import SAMNeuron\n",
    "import csv\n",
    "from PIL import Image\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190c9736",
   "metadata": {},
   "source": [
    "## Convert Neurons to required format\n",
    "Input the mode of the synthetic neuron and the path to the saved images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be5762c-fd86-4273-af26-f5cac2ea0f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Class: 00_laptop\n",
      "./dataset_exemplars_COCO_v3/Age/Young/00_laptop\n",
      "['laptop']\n",
      "final text_encoder_type: bert-base-uncased\n",
      "12.png\n",
      "1 faces detected\n",
      "objected detected, biased face detected: 0.68\n",
      "0.68\n",
      "9.png\n",
      "1 faces detected\n",
      "objected detected, biased face detected: 0.71\n",
      "0.71\n",
      "0.png\n",
      "3 faces detected\n",
      "objected detected, biased face detected: 0.76\n",
      "0.76\n",
      "7.png\n",
      "1 faces detected\n",
      "objected detected, biased face detected: 0.73\n",
      "0.73\n",
      "14.png\n",
      "1 faces detected\n",
      "objected detected, biased face detected: 0.68\n",
      "0.68\n",
      "13.png\n",
      "1 faces detected\n",
      "objected detected, biased face detected: 0.68\n",
      "0.68\n",
      "6.png\n",
      "2 faces detected\n",
      "objected detected, biased face detected: 0.73\n",
      "0.73\n",
      "1.png\n",
      "1 faces detected\n",
      "objected detected, biased face detected: 0.75\n",
      "0.75\n",
      "8.png\n",
      "1 faces detected\n",
      "objected detected, biased face detected: 0.7066666666666667\n",
      "0.71\n",
      "2.png\n",
      "2 faces detected\n",
      "objected detected, biased face detected: 0.74\n",
      "0.74\n",
      "5.png\n",
      "1 faces detected\n",
      "objected detected, biased face detected: 0.74\n",
      "0.74\n",
      "10.png\n",
      "5 faces detected\n",
      "objected detected, biased face detected: 0.7\n",
      "0.7\n",
      "4.png\n",
      "1 faces detected\n",
      "objected detected, biased face detected: 0.74\n",
      "0.74\n",
      "3.png\n",
      "1 faces detected\n",
      "objected detected, biased face detected: 0.74\n",
      "0.74\n",
      "11.png\n",
      "2 faces detected\n",
      "objected detected, biased face detected: 0.7\n",
      "0.7\n",
      "Processing Class: activations.csv\n",
      "./dataset_exemplars_COCO_v3/Age/Young/activations.csv\n",
      "activations.csv\n"
     ]
    }
   ],
   "source": [
    "mode = 'mono'\n",
    "data_path = \"./dataset_exemplars_COCO_v3/\"\n",
    "\n",
    "\n",
    "data_path = os.path.join(data_path, mode)\n",
    "num_exemplars = 15\n",
    "data_dict = []\n",
    "all_activations = []\n",
    "all_images = []\n",
    "labels = []\n",
    "count_res = 0\n",
    "base = os.path.join(\"./synthetic_neurons_v3\", mode)\n",
    "\n",
    "if os.path.exists(os.path.join(base, \"data.json\")):\n",
    "    with open(os.path.join(base, \"data.json\"), 'r') as file:\n",
    "        data_dict = json.load(file)\n",
    "    all_activations = np.load(os.path.join(base, \"activations.npy\")).tolist()\n",
    "    all_images = np.load(os.path.join(base, \"images.npy\")).tolist()\n",
    "    all_masks = np.load(os.path.join(base, \"masks.npy\")).tolist()\n",
    "    labels = np.load(os.path.join(base, \"masks.npy\")).tolist()\n",
    "    count_res = len(all_images)\n",
    "\n",
    "# Expects data in format:\n",
    "# data_path/label\n",
    "# For multi-label neurons:\n",
    "# data_path/label1_label2\n",
    "for x in sorted(os.listdir(data_path)[count_res:]):\n",
    "    print(\"Processing Class: \"+x)\n",
    "    current_path = os.path.join(data_path, x)\n",
    "    print(current_path)\n",
    "    if not(os.path.isdir(current_path)) or (\"ipynb_checkpoints\" in x):\n",
    "        print(x)\n",
    "        continue\n",
    "    labels = [x.rsplit('_')[1]]\n",
    "    print(labels)\n",
    "    neuron = SAMNeuron(labels=labels, mode=mode)\n",
    "    os.makedirs(os.path.join(base, 'masks', x),exist_ok=True)\n",
    "    os.makedirs(os.path.join(base, 'masked_images', x),exist_ok=True)\n",
    "    os.makedirs(os.path.join(base, 'images', x),exist_ok=True)\n",
    "    os.makedirs(base+\"data/\" +x,exist_ok=True)\n",
    "    logits = []\n",
    "    names = []\n",
    "    images = []\n",
    "    masks = []\n",
    "    for y in os.listdir(current_path):\n",
    "        print(y)\n",
    "        if (\"ipynb_checkpoints\" in y):\n",
    "            continue\n",
    "        if y[-3:] == 'txt'or y[-3:] == 'csv': continue\n",
    "        try:\n",
    "            input_image = Image.open(os.path.join(current_path, y))\n",
    "            [curr_logit], [image] = neuron.calc_activations([input_image])\n",
    "            mask = Image.fromarray(255 * mask.astype(np.uint8))\n",
    "            mask = mask.resize((224, 224), Image.Resampling.LANCZOS)\n",
    "            mask.save(os.path.join(base, 'masks', x, y))\n",
    "            masks.append(np.array(mask))\n",
    "            print(curr_logit)\n",
    "            inside = np.array(mask > 0)\n",
    "            outside = np.array(mask == 0)\n",
    "            masked_image = image * inside + 0 * image * outside\n",
    "            display(masked_image)\n",
    "            names.append(y)\n",
    "            masked_image.save(os.path.join(base, 'masked_images', x, y))\n",
    "            image = Image.fromarray(image.astype(np.uint8))\n",
    "            image = image.resize((224, 224), Image.Resampling.LANCZOS)\n",
    "            image.save(os.path.join(base, 'images', x, y))\n",
    "            images.append(np.array(image))\n",
    "            logits.append(curr_logit)\n",
    "        except Exception as e:\n",
    "            # embed()\n",
    "            print(e)\n",
    "            print(\"failed processing image \"+\"/\"+x+\"/\"+y)                \n",
    "            continue\n",
    "        # count+=1\n",
    "    indx = np.argsort(-np.array(logits))\n",
    "    indx = indx[:num_exemplars]\n",
    "    if len(indx)<num_exemplars: \n",
    "        print(\"not enough images \"+\"/\" + x + \"/\" + y) \n",
    "        break\n",
    "    activation_list = np.array(logits)[indx]\n",
    "    image_list = np.array(names)[indx]\n",
    "    data_dict.append({\"label\": x, \"image_names\": image_list.tolist(), \"activations\": activation_list.tolist()})\n",
    "    all_activations.append(activation_list)\n",
    "    all_images.append(np.array(images)[indx])\n",
    "    all_masks.append(np.array(masks)[indx])\n",
    "    labels.append(x)\n",
    "    with open(os.path.join(base, \"data.json\"), 'w') as file:\n",
    "        json.dump(data_dict, file, indent=4)\n",
    "    np.save(os.path.join(base, \"activations.npy\"), np.array(all_activations))\n",
    "    np.save(os.path.join(base, \"images.npy\"), np.array(all_images))\n",
    "    np.save(os.path.join(base, \"masks.npy\"), np.array(all_masks))\n",
    "    np.save(os.path.join(base, \"labels.npy\"), np.array(labels))\n",
    "\n",
    "with open(os.path.join(base, \"activations.csv\"), 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for row in all_activations:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a2f0b3-ceeb-4d62-a177-9232878d0811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
